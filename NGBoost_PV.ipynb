{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "from ngboost import NGBRegressor\n",
    "\n",
    "import properscoring as prscore\n",
    "\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read and preprocess the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('power_weather_data.csv')\n",
    "\n",
    "# csv file MUST contain 'date' and 'Power' fields\n",
    "# optional: weather data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date'] = pd.to_datetime(df['date'], format='%m/%d/%Y %H:%M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour'] = df['date'].apply(lambda x: x.hour )\n",
    "df['month'] = df['date'].apply(lambda x: x.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['hour_sin'] = np.sin(df['hour'] * 2 * np.pi/24)\n",
    "# df['hour_cos'] = np.cos(df['hour'] * 2 * np.pi/24)\n",
    "df['month_sin'] = np.sin(df['month'] * 2 * np.pi/12)\n",
    "df['month_cos'] = np.cos(df['month'] * 2 * np.pi/12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[(df['hour']>=6) & (df['hour']<=21)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(['hour', 'month'], axis=1)\n",
    "df = df.drop(['month'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = df['Power']\n",
    "\n",
    "PowerData = pd.concat([P.shift(3), P.shift(2), P.shift(1)], axis=1)\n",
    "PowerData.columns = ['t-45', 't-30', 't-15']\n",
    "\n",
    "df = pd.concat([df, PowerData.reindex(df.index)], axis=1)\n",
    "    \n",
    "df = df.fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weeks = [['2018-03-01', '2019-03-15']]\n",
    "\n",
    "val_days = 14\n",
    "\n",
    "# n_points_day = 4 * 24\n",
    "n_points_day = 4 * 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = []\n",
    "\n",
    "for w in weeks:\n",
    "    \n",
    "    w_start = datetime.strptime(w[0]+\" 00:00\", '%Y-%m-%d %H:%M')\n",
    "    w_end = datetime.strptime(w[1]+\" 23:59\", '%Y-%m-%d %H:%M')\n",
    "    \n",
    "    dfs.append(df[(df['date'] > w_start) & (df['date'] < w_end)])\n",
    "    \n",
    "n_sets = len(dfs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ = []\n",
    "X_test_ = []\n",
    "y_train_ = []\n",
    "y_test_ = []\n",
    "\n",
    "x_scaler = []\n",
    "y_scaler = []\n",
    "\n",
    "t_train = []\n",
    "t_test = []\n",
    "\n",
    "for i in range(n_sets):\n",
    "\n",
    "    train = dfs[i][:int(-n_points_day*val_days)]\n",
    "    test = dfs[i][int(-n_points_day*val_days):]\n",
    "    \n",
    "    X_tr = train.drop(['Power','date'], axis=1).values\n",
    "    X_t = test.drop(['Power','date'], axis=1).values\n",
    "    \n",
    "    y_tr = train['Power'].values\n",
    "    y_t = test['Power'].values\n",
    "    \n",
    "    x_sc = MinMaxScaler()\n",
    "    y_sc = MinMaxScaler()\n",
    "#     x_sc = StandardScaler()\n",
    "#     y_sc = StandardScaler()\n",
    "    x_sc.fit(X_tr)\n",
    "    y_sc.fit(y_tr.reshape(-1, 1))  #reshape only because fit needs a 2d array\n",
    "    x_scaler.append(x_sc)\n",
    "    y_scaler.append(y_sc)\n",
    "    \n",
    "    X_train_.append(x_sc.transform(X_tr))\n",
    "    X_test_.append(x_sc.transform(X_t))\n",
    "    y_train_.append(y_sc.transform(y_tr.reshape(-1, 1)))\n",
    "    y_test_.append(y_sc.transform(y_t.reshape(-1, 1)))\n",
    "    \n",
    "    t_train.append(dfs[i].iloc[:int(-n_points_day*val_days)]['date'].values)\n",
    "    t_test.append(dfs[i].iloc[int(-n_points_day*val_days):]['date'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_\n",
    "X_test = X_test_\n",
    "y_train = y_train_\n",
    "y_test = y_test_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_learner = DecisionTreeRegressor(\n",
    "    criterion=\"friedman_mse\",\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    min_weight_fraction_leaf=0.0,\n",
    "    max_depth=3,\n",
    "    splitter=\"best\",\n",
    "    random_state=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ngbs = []\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for i in range(n_sets):\n",
    "    \n",
    "    X_train_i = X_train[i]\n",
    "    y_train_i = y_train[i]\n",
    "\n",
    "    ngb = NGBRegressor(Base=tree_learner, n_estimators=1000).fit(X_train_i, y_train_i.ravel())\n",
    "    \n",
    "    ngbs.append(ngb)\n",
    "\n",
    "end = time.time()\n",
    "print((end - start)/n_sets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = []\n",
    "y_hat = []\n",
    "upper_hat = []\n",
    "lower_hat = []\n",
    "\n",
    "for i in range(n_sets):\n",
    "    \n",
    "    ngb = ngbs[i]\n",
    "    X_test_i = X_test[i]\n",
    "    y_test_i = y_test[i]\n",
    "    \n",
    "    # For multi-step ahead prediction\n",
    "    y_first = ngb.predict(X_test_i[:3])\n",
    "    \n",
    "    y_3 = y_first[3-3]\n",
    "    y_2 = y_first[3-2]\n",
    "    y_1 = y_first[3-1]\n",
    "    for j in range(3, X_test[i].shape[0]):\n",
    "        X_test_i[j][-3] = y_3\n",
    "        X_test_i[j][-2] = y_2\n",
    "        X_test_i[j][-1] = y_1\n",
    "        y_pred_j = ngb.pred_dist(X_test_i[j].reshape(1, -1)).loc\n",
    "        y_3 = y_2\n",
    "        y_2 = y_1\n",
    "        y_1 = y_pred_j\n",
    "    # end of multi-step ahead\n",
    "    \n",
    "    y_pred = ngb.predict(X_test_i)\n",
    "    y_dists = ngb.pred_dist(X_test_i)\n",
    "    \n",
    "    mean = y_dists.loc\n",
    "    std = y_dists.scale\n",
    "    \n",
    "    mean = y_scaler[i].inverse_transform(mean.reshape(1, -1))\n",
    "    std = y_scaler[i].inverse_transform(std.reshape(1, -1))\n",
    "    mean = mean.flatten()\n",
    "    std = std.flatten()\n",
    "    \n",
    "    real_y_test = y_scaler[i].inverse_transform(y_test_i)\n",
    "    real_y_test = real_y_test.flatten()\n",
    "    \n",
    "    lower = []\n",
    "    upper = []\n",
    "    for s in range(1,4):\n",
    "        lower = lower + [mean - s * std]\n",
    "        upper = upper + [mean + s * std]\n",
    "    \n",
    "    y_hat.append(mean)\n",
    "    y.append(real_y_test)\n",
    "    lower_hat.append(lower)\n",
    "    upper_hat.append(upper)\n",
    "    \n",
    "    # Deterministic metrics\n",
    "    MAE = mean_absolute_error(real_y_test, mean)\n",
    "    RMSE = mean_squared_error(real_y_test, mean, squared=False)\n",
    "    MBE = np.mean(mean - real_y_test)\n",
    "    print(f'MAE: {MAE:.3f}')\n",
    "    print(f'RMSE: {RMSE:.3f}')\n",
    "    print(f'MBE: {MBE:.3f}')\n",
    "    \n",
    "    # Probabilistic metrics\n",
    "    PICP = PICP_func(real_y_test, lower[1], upper[1])\n",
    "    PINAW = PINAW_func(real_y_test, lower[1], upper[1])\n",
    "    C = prscore.crps_gaussian(real_y_test, mu=mean, sig=std)\n",
    "    CRPS = C.mean()\n",
    "    print(f'PICP: {PICP:.3f}')\n",
    "    print(f'PINAW: {PINAW:.3f}')\n",
    "    print(f'CRPS: {CRPS:.3f}')\n",
    "    print('\\n') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.initjs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "ngb = ngbs[i]\n",
    "\n",
    "features = list(dfs[i].columns)[2:]\n",
    "\n",
    "explainer = shap.TreeExplainer(ngb, model_output=0)  # menan (point forecast): model_output=0, std (uncertainty):  model_output=1   \n",
    "shap_values = explainer.shap_values(X_train[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Summary Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "shap.summary_plot(shap_values, X_train[i], feature_names=features, show=True, plot_size=(15,8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "shap.summary_plot(shap_values, X_train[i], feature_names=features, show=True, plot_size=(15,8), plot_type='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP Interaction Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature indeces:\n",
    "# 0: Temperature\n",
    "# 1: Humidity\n",
    "# 2: precipitation\n",
    "# 3: wind speed\n",
    "# 4: radiation\n",
    "# 5: hour\n",
    "# 6: month_sin\n",
    "# 7: month_cos\n",
    "# 8: t-45\n",
    "# 9: t-30\n",
    "# 10: t-15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_interaction_values = explainer.shap_interaction_values(X_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "shap.dependence_plot((10,4), shap_interaction_values, X_tr, feature_names=features, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Force plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "shap.force_plot(explainer.expected_value, shap_values[851,:], features=features,link='logit', matplotlib=True, figsize=(10, 3),contribution_threshold=0.025 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs[i].iloc[851]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
